import json
import re
from typing import List, Dict

import google.generativeai as genai
from faster_whisper import WhisperModel

from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

from app.models import Lead

# -------------------------------------------------------------------
# GLOBAL MODELS
# -------------------------------------------------------------------

# ---------- Faster Whisper (local STT) ----------
whisper_model = WhisperModel(
    "base",
    device="cpu",
    compute_type="int8"
)

# ---------- Local Intent Classifier (BETO Sentiment) ----------
intent_tokenizer = AutoTokenizer.from_pretrained("finiteautomata/beto-sentiment-analysis")
intent_model_fast = AutoModelForSequenceClassification.from_pretrained(
    "finiteautomata/beto-sentiment-analysis"
)
label_map = {0: "NEG", 1: "NEU", 2: "POS"}

# ---------- Gemini for reply generation ONLY ----------
reply_model = genai.GenerativeModel("models/gemini-flash-latest")


# -------------------------------------------------------------------
# FAST LOCAL INTENT CLASSIFICATION
# -------------------------------------------------------------------
def classify_intent_fast(text: str) -> str:
    """
    Super fast Spanish intent classifier (5‚Äì10 ms).
    Maps sentiment ‚Üí (INTERESTED, NOT_INTERESTED, FOLLOW_UP, NEUTRAL)
    """

    inputs = intent_tokenizer(text, return_tensors="pt", truncation=True)
    with torch.no_grad():
        logits = intent_model_fast(**inputs).logits

    pred_id = int(torch.argmax(logits))
    sentiment = label_map[pred_id]  # NEG, NEU, POS

    low = text.lower()

    # ------- Mapping rules -------
    if sentiment == "NEG" or any(p in low for p in [
        "no quiero", "no me interesa", "caro", "no gracias", "no por ahora"
    ]):
        return "NOT_INTERESTED"

    if any(p in low for p in [
        "luego", "m√°s tarde", "mas tarde", "despu√©s", "despues"
    ]):
        return "FOLLOW_UP"

    if sentiment == "POS" or any(p in low for p in [
        "interesado", "interesa", "cu√©ntame", "cuentame", "quiero saber"
    ]):
        return "INTERESTED"

    return "NEUTRAL"


# -------------------------------------------------------------------
# TRANSCRIBE + INTENT
# -------------------------------------------------------------------
def transcribe_and_analyze(file_path: str, mime_type: str = "audio/webm"):
    """
    Transcribe audio using Faster Whisper + classify intent locally.
    """

    print("üé§ Iniciando transcripci√≥n con Faster Whisper...")

    segments, info = whisper_model.transcribe(
        file_path,
        language="es",
        beam_size=5,
        vad_filter=True,
        vad_parameters={"min_silence_duration_ms": 300},
    )

    print("üåé Idioma detectado:", info.language)
    print("üìä Probabilidad idioma:", info.language_probability)

    full_text = []
    print("üîé Segmentos detectados:")
    for seg in segments:
        print(f"  üü¶ [{seg.start:.2f}s ‚Üí {seg.end:.2f}s] {seg.text}")
        full_text.append(seg.text)

    transcript = " ".join(full_text).strip()
    print("üìù TRANSCRIPCI√ìN FINAL:", transcript or "<vac√≠a>")

    if not transcript:
        print("‚ö†Ô∏è No se detect√≥ texto. Intent = NEUTRAL")
        return {"transcript": "", "intent": "NEUTRAL"}

    # ---------- LOCAL INTENT ----------
    print("‚ö° Clasificando intenci√≥n localmente...")
    intent = classify_intent_fast(transcript)
    print("üîÆ INTENCI√ìN DETECTADA:", intent)

    return {
        "transcript": transcript,
        "intent": intent,
    }


# -------------------------------------------------------------------
# BUILD RESPONSE (GEMINI ‚Äî SHORT ANSWERS)
# -------------------------------------------------------------------
def build_response(
    lead: Lead,
    user_text: str,
    intent: str,
    history: List[Dict[str, str]],
) -> str:

    history_block = ""
    for turn in history[-2:]:
        history_block += f"Usuario: {turn.get('user')}\nAgente: {turn.get('agent')}\n\n"

    print("üßµ HISTORY BLOCK SENT TO GEMINI:")
    print(history_block or "[Sin mensajes previos]")

    system_block = f"""
Eres un asesor comercial colombiano, profesional y cercano.
Respuestas SIEMPRE cortas (m√°ximo 3 oraciones, 12 palabras c/u).
Nunca suenes rob√≥tico. Habla como vendedor experto.

Cliente: {lead.name}
Veh√≠culo: {lead.car_name} {lead.car_model}
Precio estimado: {lead.car_price_cop} COP

Reglas por intenci√≥n:
- NOT_INTERESTED:
    ‚Ä¢ Intenta UNA sola vez m√°s con una respuesta emp√°tica, breve y sin presi√≥n.
    ‚Ä¢ Si vuelve a mostrar desinter√©s, agradece y cierra suavemente.
- FOLLOW_UP:
    ‚Ä¢ Ofrece enviar informaci√≥n o llamar luego.
- INTERESTED:
    ‚Ä¢ Recomienda el servicio adecuado y pregunta fecha/hora.
    ‚Ä¢ NO pidas direcci√≥n al cliente.
    ‚Ä¢ En su lugar, recomienda una sede imaginaria: Sede Norte, Sede Centro o Sede Sur.
- NEUTRAL:
    ‚Ä¢ Haz una pregunta simple para avanzar la conversaci√≥n.

Regla importante:
- NO preguntes por direcci√≥n del cliente.
- Si necesitas ofrecer lugares, usa √∫nicamente:
    ‚Ä¢ Sede Norte
    ‚Ä¢ Sede Centro
    ‚Ä¢ Sede Sur
  Nunca menciones direcciones reales ni detalles log√≠sticos.

Servicios:
1) Premium: lavado + polichado + partes negras + 20 fotos (350k + IVA)
2) Intermedia: lavado + 20 fotos (200k + IVA)
3) Econ√≥mica: solo fotos (100k + IVA)
"""

    history_text = f"Historial breve:\n{history_block or '[Sin mensajes previos]'}\n"

    user_block = (
        f"Mensaje del cliente: \"{user_text}\"\n"
        f"Intenci√≥n detectada: {intent}\n\n"
        "Responde con m√°ximo 3 oraciones cortas."
    )

    full_prompt = system_block + "\n" + history_text + "\n" + user_block

    response = reply_model.generate_content(
        full_prompt,
    )

    text = (response.text or "").strip()
    print("ü§ñ RESPUESTA GEMINI:", text)
    return text